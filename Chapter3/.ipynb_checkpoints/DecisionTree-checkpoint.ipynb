{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Learning\n",
    "\n",
    "Decision tree learning is one of the most widely used and practical methods for inductive inference. It is a method for approximating discrete-valued functions that is robust to noisy data and capable of learning disjunctive expressions. This chapter describes a family of decision tree learning algorithms that includes widely used algorithms such as ID3, ASSISTANT, and C4.5. These decision tree learning methods search a completely expressive hypothesis space and thus avoid the difficulties of restricted hypothesis spaces. Their inductive bias is a preference for small trees over large trees.\n",
    "\n",
    "In general, decision trees represent a disjunction of conjunctions of constraints on the attribute values of instances. Each path from the tree root to a leaf corresponds to a conjunction of attribute tests, and the tree itself to a disjunction of these conjunctions. \n",
    "\n",
    "\n",
    "## 1.1 Appropriate problems for decision tree learning\n",
    "\n",
    "Decision tree is very helpful in scenarios where:\n",
    "- Where instances are represented as attribute value pairs. There are discrete values of attributes. For example, Temperature can be *Hot, Mild, Cold*\n",
    "- Target function has discrete output values. It can be binary (*yes* or *no*) or can have more than two classes.\n",
    "- Disjunctive descriptions may be required to express the hypothesis.\n",
    "- Training data may contain errors\n",
    "- Training data might have some missing attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "## 1.2 Basic Decision Tree Algorithm\n",
    "\n",
    "Most of the approaches are based on top-down greedy approaches of searching the right decision tree from the space of decision trees. It starts of by asking which attribute is statistically the best to split the data at root node.\n",
    "\n",
    "### 1.2.1 ID3 algorithm\n",
    "\n",
    "---\n",
    "***Alogirthm 1.2.1***:\n",
    "ID3(Examples, Target_attribute, Attributes):\n",
    "1. Create a root node.\n",
    "2. **If** all example in *Examples* are positive then ***return Root with label +***\n",
    "3. **If** all example in *Examples* are negative then ***return Root with label -***\n",
    "4. **If** *Attributes* is empty then ***return Root with label = most common Target_attribute in Examples***\n",
    "5. **Else**:\n",
    "   - $A \\leftarrow$ Best attribute from *Attributes* which best\\* classifies *Examples*\n",
    "   - Set $A$ as decision attribute for $Root$\n",
    "   - For each possible value $v_i$ of $A$:\n",
    "       - Add a new tree branch below *Root*, corresponding to the test $A = v_i$\n",
    "       - **Let** $Examples_{v_i}$ be the subset of *Examples* that have value $v_i$ for $A$\n",
    "       - **If** $Examples_{v_i}$ is empty:\n",
    "           - **Then** Below this new branch add a new leaf node with label = most common value of *Target_attribute in Examples*\n",
    "           - **Else** Below this new branch add a subtree ID3($Examples_{v_i}$, $Target\\_attribute$, $Attribute - \\{A\\}$)\n",
    "---\n",
    "**\\*Best**: Best attribute is the one with the highest information gain.\n",
    "\n",
    "### 1.2.2 How to decide the best attribute ?\n",
    "\n",
    "There are multiple way to decide the best attribute one of them is ***Information Gain***.\n",
    "\n",
    "### 1.2.3 Information Content\n",
    "\n",
    "This definition is taken from information theory. We define something called as *information content*. Given a random variable $X$ with a probability mass function $p_X(x)$, the self-information of measuring $X$ as outcome $x$ is defined as\n",
    " $$I_X(x) = - log_2(p_X(x))$$\n",
    "\n",
    " The unit of information is called *Shannon* (or simply bit).<br>\n",
    "**Below is the implementation of Information Content**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:07:00.110859Z",
     "start_time": "2020-01-10T02:06:59.305292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Ix(x)\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "def InformationContent(x):\n",
    "    assert 0 <= x <= 1\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return -math.log(x, 2)\n",
    "x = [i*0.001 for i in range(1, 1000)]\n",
    "y = [InformationContent(i) for i in x]\n",
    "plot.close()\n",
    "plot.title(\"Information Content\")\n",
    "plot.xlabel(r'$p_X(x)$')\n",
    "plot.ylabel(r'$I_X(x) = -log_2(p_X(x))$')\n",
    "plot.plot(x, y)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Information Gain\n",
    "Clearly *information content* is more in outcomes which are less frequent.\n",
    "Using this we define *entropy* as average $I_X(x)$ (information content) for a sample space $S$.\n",
    "$$Entropy(S) = -\\sum_{i \\in S} p_i log_2 p_i$$\n",
    "In other words, $Entropy(S) = E[I_x(x)]$ (expected or average information content)\n",
    "Entropy can be seen as the measure of average number of bits needed to communicate a message from space $S$. \n",
    "For more information on the rationale behind defining $Entropy$ like this read the following <a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)#Rationale\">Wiki Page</a>\n",
    "\n",
    "We define the Information Gain for a sample $S$ and attribute $A$ as:\n",
    "$$Gain(S, A) = Entropy(S) - \\sum_{v \\in A} \\frac{|S_v|}{|S|}Entropy(S_v)$$\n",
    "\n",
    "The *entropy* is minimum when each outcome is equally likely. (This can be seen in the entropy diagram)<br>\n",
    "**Below is the implementation of Information Gain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:07:01.188952Z",
     "start_time": "2020-01-10T02:07:00.117101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.7580093118615405"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing\n",
    "def EpsEquals(f1:float, f2: float, eps: float=10**-6):\n",
    "    return abs(f1 - f2) <= eps\n",
    "\n",
    "def Entropy(p:typing.List[float]):\n",
    "    assert EpsEquals(sum(p), 1.0)\n",
    "    return sum([pi * InformationContent(pi) for pi in p])\n",
    "\n",
    "x = [[i * 0.001, 1 - i * 0.001] for i in range(1000)]\n",
    "y = [Entropy(xi) for xi in x]\n",
    "plot.close()\n",
    "plot.title(\"Entropy\")\n",
    "plot.xlabel(\"p\")\n",
    "plot.ylabel(r'$plog_2(p) +(1-p)log_2(1-p)$')\n",
    "plot.plot(x, y)\n",
    "plot.show()\n",
    "Entropy([1/2, 1/3, 1/18, 1 - 1/3 - 1/2 - 1/18 - 1/19 - 1/20, 1/19, 1/20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the implementation of ID3 decision tree algorithm**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:07:02.085624Z",
     "start_time": "2020-01-10T02:07:01.195270Z"
    },
    "code_folding": [
     74,
     197
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ TestData = {'Sky': 'Blue', 'Grass': 'Yellow'} NodeLabel = Don't Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Gloomy', 'Grass': 'Yellow'} NodeLabel = Don't Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Dark', 'Grass': 'Yellow'} NodeLabel = Don't Play ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"485pt\" height=\"218pt\"\r\n",
       " viewBox=\"0.00 0.00 485.49 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-214 481.491,-214 481.491,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"238.746\" cy=\"-192\" rx=\"181.968\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"238.746\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Sky&quot;, &quot;Gain&quot;:&quot;0.3219280948873623&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.7457\" cy=\"-105\" rx=\"48.9926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.7457\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Don&#39;t Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.507,-174.395C184.882,-168.676 169.608,-162.159 155.746,-156 132.613,-145.722 106.909,-133.73 86.4928,-124.067\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.7567,-120.792 77.2218,-119.667 84.7554,-127.116 87.7567,-120.792\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"195.246\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Sky == &#39;Dark&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"238.746\" cy=\"-105\" rx=\"123.478\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"238.746\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Grass&quot;, &quot;Gain&quot;:&quot;1.0&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.746,-173.799C238.746,-162.163 238.746,-146.548 238.746,-133.237\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242.246,-133.175 238.746,-123.175 235.246,-133.175 242.246,-133.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"277.246\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Sky == &#39;Blue&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>6</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"428.746\" cy=\"-105\" rx=\"48.9926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"428.746\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Don&#39;t Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;6 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.962,-174.263C291.255,-168.534 306.171,-162.045 319.746,-156 343.331,-145.497 369.643,-133.437 390.506,-123.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"392.075,-126.923 399.679,-119.546 389.134,-120.571 392.075,-126.923\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"402.746\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Sky == &#39;Gloomy&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"178.746\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"178.746\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Play</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.716,-87.8255C191.17,-82.9168 184.243,-76.7173 179.746,-69 175.778,-62.1926 174.498,-53.9283 174.498,-46.0955\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.008,-46.0642 175.16,-35.8591 171.022,-45.6123 178.008,-46.0642\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"228.246\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Grass == &#39;Green&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"298.746\" cy=\"-18\" rx=\"48.9926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"298.746\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Don&#39;t Play</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260.038,-87.2203C265.962,-81.8431 272.052,-75.5675 276.746,-69 281.842,-61.8688 286.126,-53.3698 289.52,-45.4201\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.773,-46.7101 293.213,-36.1244 286.268,-44.1255 292.773,-46.7101\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"337.246\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Grass == &#39;Yellow&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0xe36ebd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTANT NOTE\n",
    "#This piece of code is not intended for production scale and \n",
    "#should ideally be used for pedagogical purposes.\n",
    "#Use it at your own risk\n",
    "\n",
    "#ID3 implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "GRAPHVIZ_PATH = r'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + GRAPHVIZ_PATH\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_name:str=\"_null_\", label:str=\"_null_\", test:str=\"_null_\", is_leaf:bool=False):\n",
    "        self._children = []\n",
    "        self.name = node_name\n",
    "        self.label = label\n",
    "        self.test = test\n",
    "        self.leaf = is_leaf\n",
    "        pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    def add_child(self, node):\n",
    "        self._children.append(node)\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self._children\n",
    "    \n",
    "    def set_name(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "    def set_label(self, label: str):\n",
    "        self.label =str(label)\n",
    "        \n",
    "    def set_test(self, test: typing.List[str]):\n",
    "        self.test = test\n",
    "    \n",
    "    def set_leaf(self):\n",
    "        self.leaf = True\n",
    "    \n",
    "    def visualize(self):\n",
    "        digraph = Digraph(comment=\"Tree\")\n",
    "        Node._get_graph(self, digraph, [0])\n",
    "        return digraph\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_graph(node, digraph: Digraph, unique_suff:typing.List[int]):\n",
    "        unique_suff[0] += 1\n",
    "        curr_node_name = str(unique_suff[0])\n",
    "        digraph.node(curr_node_name, node.label)\n",
    "        if not node.leaf:\n",
    "            for child in node._children:\n",
    "                child_name = str(unique_suff[0] + 1)\n",
    "                Node._get_graph(child, digraph, unique_suff)\n",
    "                digraph.edge(curr_node_name, child_name, label=\"%s %s '%s'\" % tuple(child.test))\n",
    "\n",
    "class ID3:\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[str], populate_inner_properties: bool=True):\n",
    "        self.attributes = list(train_data.columns)\n",
    "        self.distinct_labels = set(labels)\n",
    "        self.train_data: pd.DataFrame = train_data.copy(deep=True)\n",
    "        self.train_data[\"_index_\"] = range(0, len(train_data))\n",
    "        self.label_dictionary = {i:labels[i] for i in range(len(labels))}\n",
    "        self.labels = labels\n",
    "        self.attribute_values = None\n",
    "        self._model = None\n",
    "        if populate_inner_properties:\n",
    "            self.populate()\n",
    "    \n",
    "    def populate(self):\n",
    "        self.attribute_values = {attr: set(self.train_data[attr].unique()) for attr in self.attributes}\n",
    "    \n",
    "    @staticmethod\n",
    "    def _entropy(freq: typing.List[int]):\n",
    "        cum_sum = sum(freq)\n",
    "        p = [freq[i]/cum_sum for i in range(len(freq))]\n",
    "        entropy = Entropy(p)\n",
    "        return entropy\n",
    "    \n",
    "    def get_best_attribute(self, df: pd.DataFrame, attributes: typing.List[str], labels: typing.List[str]):\n",
    "        cur_label_cnt_dict = ID3._get_label_count_dict(labels)\n",
    "        cur_freq = [cur_label_cnt_dict[key] for key in cur_label_cnt_dict]\n",
    "        cur_total = sum(cur_freq)\n",
    "        cur_entropy = ID3._entropy(cur_freq)\n",
    "        max_gain = -math.inf\n",
    "        split_attr = None\n",
    "        for attr in attributes:\n",
    "            distinct_values = self.get_distinct_values(attr, df, labels)\n",
    "            partial = 0\n",
    "            gain = 0\n",
    "            for val in distinct_values:\n",
    "                new_df = self.eval_attr_condition(attr, df, val)\n",
    "                if len(new_df) == 0:\n",
    "                    continue\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_df[\"_index_\"]]\n",
    "                new_label_cnt_dict = ID3._get_label_count_dict(new_labels)\n",
    "                new_freq = [new_label_cnt_dict[key] for key in new_label_cnt_dict]\n",
    "                new_entropy = ID3._entropy(new_freq)\n",
    "                new_total = sum(new_freq)\n",
    "                new_partial = new_total / cur_total * new_entropy\n",
    "                partial += new_partial\n",
    "            gain = cur_entropy - partial\n",
    "            if gain > max_gain:\n",
    "                split_attr = attr\n",
    "                max_gain = gain\n",
    "        return [split_attr, max_gain]\n",
    "    \n",
    "    def get_distinct_values(self, attr: str, df: pd.DataFrame, labels: typing.List[str]):\n",
    "        return self.attribute_values[attr]\n",
    "    \n",
    "    def eval_attr_condition(self, attr, df, val):\n",
    "        return df[df[attr] == val]\n",
    "    \n",
    "    def get_test_condition(self, attr, value):\n",
    "        return \"==\"\n",
    "    \n",
    "    def get_test_value(self, attr, value):\n",
    "        return value\n",
    "    \n",
    "    def get_distinct_labels(self, labels):\n",
    "        return set(labels)        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_label_count_dict(labels: typing.List[str]):\n",
    "        distinct_labels = set(labels)\n",
    "        label_cnt_dict =  {l : labels.count(l) for l in distinct_labels}\n",
    "        return label_cnt_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_label_with_high_freq(labels: typing.List[str]):\n",
    "        label_cnt_dict = ID3._get_label_count_dict(labels)\n",
    "        maxi = -math.inf\n",
    "        max_label = labels[0]\n",
    "        for label in label_cnt_dict:\n",
    "            if label_cnt_dict[label] > maxi:\n",
    "                maxi = label_cnt_dict[label]\n",
    "                max_label = label\n",
    "        return max_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def _printExamples(name: str, df: pd.DataFrame):\n",
    "        print(\"------------------------\")\n",
    "        print(name)\n",
    "        print(df)\n",
    "        print(\"------------------------\")\n",
    "    \n",
    "    def id3(self, example: pd.DataFrame, labels: typing.List[str], attribute_set: set):\n",
    "        example[\"_labels_\"] = labels\n",
    "        root_node = Node()\n",
    "        distinct_labels = self.get_distinct_labels(labels)\n",
    "        if len(distinct_labels) == 1: # If all labels are of same type\n",
    "            root_node.set_label(labels[0])\n",
    "            root_node.set_name(\"LeafNode\")\n",
    "            root_node.set_leaf()\n",
    "        elif len(attribute_set) == 0: # If there are no attributes left\n",
    "            root_node.set_label(ID3._get_label_with_high_freq(labels))\n",
    "            root_node.set_name(\"LeafNode\")\n",
    "            root_node.set_leaf()\n",
    "        else: # We need to choose the best attribute and then recursively build the tree\n",
    "            best_attr, entropy_value = self.get_best_attribute(example, list(attribute_set), labels)\n",
    "            # ID3._printExamples(\"Best attribute %s %s\" % (best_attr, entropy_value), example)\n",
    "            root_node.set_label(\"{{\\\"Attr\\\":\\\"{}\\\", \\\"Gain\\\":\\\"{}\\\"}}\".format(best_attr, entropy_value))\n",
    "            for value in self.get_distinct_values(best_attr, example, labels):\n",
    "                new_examples = self.eval_attr_condition(best_attr, example, value)\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_examples[\"_index_\"]]\n",
    "                new_examples[\"_index_\"] = range(0, len(new_examples))\n",
    "                new_child_node:Node = None\n",
    "                new_attribute_set = set(attribute_set)\n",
    "                new_attribute_set.remove(best_attr)\n",
    "                if len(new_examples) == 0:\n",
    "                    new_child_node = Node()\n",
    "                    new_child_node.set_label(ID3._get_label_with_high_freq(labels))\n",
    "                    new_child_node.set_leaf()\n",
    "                else:\n",
    "                    new_child_node = self.id3(new_examples, new_labels, new_attribute_set)\n",
    "                new_child_node.test = [best_attr, self.get_test_condition(best_attr, value), self.get_test_value(best_attr, value)]\n",
    "                root_node.add_child(new_child_node)\n",
    "        return root_node\n",
    "    \n",
    "    def train(self):\n",
    "        self._model = self.id3(self.train_data, self.labels, set(self.attributes))\n",
    "    \n",
    "    def evaluate_test(self, row_value, condition, val):\n",
    "        return row_value == val\n",
    "    \n",
    "    def test_row(self, cur_node, df_row):\n",
    "        if cur_node.leaf:\n",
    "            print(\"Output: [\", \"TestData =\",df_row.to_dict(), \"NodeLabel =\", cur_node.label, \"]\")\n",
    "            print()\n",
    "            return cur_node.label\n",
    "        else:\n",
    "            for child in cur_node._children:\n",
    "                attr, condition, value = child.test\n",
    "                if self.evaluate_test(df_row[attr], condition, value):\n",
    "                    # print(\"Checking Node:[\", attr, condition, value, \"TestData =\", df_row.to_dict(), \"NodeLabel =\", child.label, \"]\")\n",
    "                    return self.test_row(child, df_row)\n",
    "    \n",
    "    def test(self, df: pd.DataFrame):\n",
    "        return [self.test_row(self._model, row) for index, row in df.iterrows()]\n",
    "df = pd.DataFrame({\"Sky\":[\"Blue\", \"Blue\", \"Dark\", \"Dark\", \"Gloomy\"],\n",
    "                   \"Grass\":[\"Green\", \"Yellow\", \"Green\", \"Yellow\", \"Green\"]})\n",
    "labels =               [\"Play\", \"Don't Play\", \"Don't Play\", \"Don't Play\", \"Don't Play\"]\n",
    "df_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                        \"Grass\":[\"Yellow\", \"Yellow\", \"Yellow\"]})\n",
    "id3 = ID3(df, labels)\n",
    "id3.train()\n",
    "id3.test(df_test)\n",
    "id3._model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Hypothesis Space For Decision Tree\n",
    "\n",
    "The set of all possible decision trees is the hypothesis space for Decision Tree. It is hypothesis space of decision tree is *complete space* of finite discrete valued functions, relative to the attributes.\n",
    "Some important features about ID3 algorithm:\n",
    "- ID3 maintains only a single current hypothesis as it searches through the space of decision trees. \n",
    "- This contrasts, for example, with the version space *Candidate-Elimination* method, which maintains the set of all hypotheses consistent with the available training examples. \n",
    "- ID3 doesn't have the capability to determine how many alternative decision tree are consistent with the training data.\n",
    "- ID3 doesn't perform any backtracking. It uses kind of greedy hill climbing approach. (This gap can be filled by using post-pruning)\n",
    "- ID3 can be modified to handle noisy data. ID3 uses all training examples at each step in the search to make statistically based decisions regarding how to refine its current hypothesis. This contrasts with methods that make decisions incrementally, based on individual training examples (e.g., Find-S or Candidate-Elimination). One advantage of using statistical properties of all the examples (e.g., information gain) is that the resulting search is much less sensitive to errors in individual training examples. ID3 can be easily extended to handle noisy training data by modifying its termination criterion to accept hypotheses that imperfectly fit the training data\n",
    "\n",
    "# 1.4 Inductive Bias For Decision Tree\n",
    "\n",
    "Since ID3 follows heuristics to get to the first tree in a simple to complex tree search (like hill climbing). Therefore decision tree prefers shorter trees over larger ones. But this is not very evident because of the heuristics.\n",
    "\n",
    "**Approximate Inductive Bias** : Shorter trees are preferred.\n",
    "A better bias will be to include the heuristic in the bias.\n",
    "\n",
    "**A more closer Inductive Bias**: Shorter trees are preferred over longer trees. Trees that place high information gain attributes close to the root are preferred over those that do not.\n",
    "\n",
    "Decision tree has a *restriction bias* whereas candidate elimination has *preference bias*. *Restriction bias* is when the hypothesis space is searched incompletely and not all consistent hypothesis are considered, the algorithm stops at the first consistent hypothesis. Whereas in *preference bias* the search space itself is restricted.\n",
    "\n",
    "Decision tree prefers a shorter hypothesis based on ***Ocam Razor's Principle***, prefer the simplest hypothesis which fits the data. The Ocam Razor too has problems. The difficulty here is that there are very many small sets of hypotheses that one can define and most of them rather arcane.\n",
    "\n",
    "Why should we believe that the small set of hypotheses consisting of decision trees with short descriptions should be any more relevant than the multitude of other small sets of hypotheses that we might define? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Issues With Decision Trees\n",
    "- **Overfitting The Training Data** : This is quite possible because decision tree can grow till is able to classify the training example and stop growing after that. This can happen when the sample is size is small or there is noise in data.\n",
    "    - **Overfit definition**: Given a hypothesis space $H$, a hypothesis $h \\in H$ is said to overfit the training data if there exists some alternative hypothesis $h' \\in H$, such that h has smaller error than $h'$ over the training examples, but $h'$ has a smaller error than $h$ over the entire distribution of instances.\n",
    "    - **Avoiding overfitting**:\n",
    "        - Stop the tree growth before it perfectly fits the training data.\n",
    "        - Prune the tree after it has been trained.\n",
    "    - Criteria getting used for determining the final size of the tree:\n",
    "        - Use different set of examples other than the training one to evaluate the utility of post-puring of nodes from tree.\n",
    "        - Use all available data for training but use a statistical test like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "## 1.6 Dealing with continuous data for attributes\n",
    "\n",
    "One way to deal with continuous data is partition it into discrete values in a discreet way such that it ends up maximizing the overall information gain.\n",
    "\n",
    "One way to do this by sorting the continuous values and then checking where the values of the target function are changing.\n",
    "This approach is prescribed in [Fayyad's (1992) paper](http://web.cs.iastate.edu/~honavar/fayyad.pdf) .<br>\n",
    "\n",
    "For example consider the following table:<br>\n",
    "\n",
    "|.|.|.|.|.|.|.|\n",
    "|-|-----|----|------|------|----|----|\n",
    "|Temperature|40|48|60|72|80|90|\n",
    "|PlayTennis|No|No|Yes|Yes|Yes|No|\n",
    "\n",
    "In the above table the change happens at Temperature 48 and 60 and 80 and 90, so we introduce two discrete candidate attributes $Temperature_{>\\frac{(48 + 60)}{2}} = Temperature_{>54}$ and $Temperature_{>\\frac{(80 + 90)}{2}} = Temperature_{>85}$\n",
    "\n",
    "**Below is the implementation of ID3 with continuous attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:07:02.339183Z",
     "start_time": "2020-01-10T02:07:02.091618Z"
    },
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ TestData = {'Sky': 'Blue', 'Temp': 26} NodeLabel = Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Gloomy', 'Temp': 7} NodeLabel = Don't Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Dark', 'Temp': 2} NodeLabel = Don't Play ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"386pt\" height=\"131pt\"\r\n",
       " viewBox=\"0.00 0.00 386.27 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 382.266,-127 382.266,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"189.133\" cy=\"-105\" rx=\"189.267\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"189.133\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Temp&quot;, &quot;Gain&quot;:&quot;0.9852281360342516&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.133\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"118.133\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.96,-87.521C131.109,-82.7604 123.996,-76.6956 119.133,-69 114.876,-62.2636 113.543,-53.9307 113.585,-46.0118\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.078,-46.2337 114.301,-36.0094 110.095,-45.7339 117.078,-46.2337\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"178.633\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[25.0, inf)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"260.133\" cy=\"-18\" rx=\"48.9926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"260.133\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Don&#39;t Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.267,-87.0602C225.415,-81.925 232.594,-75.8143 238.133,-69 243.747,-62.0939 248.201,-53.5321 251.592,-45.4565\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.908,-46.5818 255.206,-35.9912 248.369,-44.0845 254.908,-46.5818\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"309.133\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[&#45;inf, 25.0)&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0xb3c6f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build on top of alread existing ID3 algorithm, inheriting from ID3 class\n",
    "\n",
    "class ID3Continuous(ID3):\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[str]):\n",
    "        super(ID3Continuous, self).__init__(train_data, labels, populate_inner_properties=False)\n",
    "        # Call attributes according the overriden values\n",
    "        data_types_dict = dict(train_data.dtypes)\n",
    "        self.data_types_dict = {attr: str(data_types_dict[attr]) for attr in data_types_dict}\n",
    "        self.continuous_attr = None\n",
    "        self.populate()\n",
    "    \n",
    "    def populate(self):\n",
    "        self.continuous_attr = set([attr for attr in self.data_types_dict if self.data_types_dict[attr] in ['float64', 'int64']])\n",
    "        self.attribute_values = {attr: set(self.train_data[attr].unique()) for attr in self.attributes if not attr in self.continuous_attr}\n",
    "    \n",
    "    def get_distinct_values(self, attr: str, df: pd.DataFrame, labels: typing.List[str]):\n",
    "        # If it is not continuous attr simply return go to base class implementation\n",
    "        if not attr in self.continuous_attr:\n",
    "            return super(ID3Continuous, self).get_distinct_values(attr, df, labels)\n",
    "        else:\n",
    "            sorted_df = df.sort_values(attr)\n",
    "            sorted_labels = [labels[idx] for idx in sorted_df[\"_index_\"]]\n",
    "            idx = 1\n",
    "            changed_values = [-math.inf]\n",
    "            #ID3._printExamples(\"Before computing change\", sorted_df)\n",
    "            while idx < len(sorted_labels):\n",
    "                if sorted_labels[idx] != sorted_labels[idx - 1]:\n",
    "                    v1 = sorted_df.iloc[idx][attr]\n",
    "                    v2 = sorted_df.iloc[idx - 1][attr]\n",
    "                    changed_values.append((v1 + v2)/2)\n",
    "                idx += 1\n",
    "            if len(changed_values) == 0 and len(sorted_df) == 1:\n",
    "                changed_values.append(sorted_df.iloc[0][attr])\n",
    "            changed_values = list(set(changed_values))\n",
    "            changed_values.sort()\n",
    "            vals = set()\n",
    "            idxValues = 1\n",
    "            vals.add((-math.inf, \"=<\", \"<\", changed_values[idxValues]))\n",
    "            while idxValues < len(changed_values):\n",
    "                vals.add((changed_values[idxValues - 1], \"=<\", \"<\", changed_values[idxValues]))\n",
    "                idxValues += 1\n",
    "            changed_values.append(math.inf)\n",
    "            vals.add((changed_values[idxValues - 1], \"=<\", \"<\", changed_values[idxValues]))\n",
    "            #print(\"changed vals\", vals)\n",
    "            return vals\n",
    "    \n",
    "    def eval_attr_condition(self, attr, df, val):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = val\n",
    "            if condition1 == \"=<\" and condition2 == \"<\":\n",
    "                return df[(value1 <= df[attr]) & (df[attr] < value2)]\n",
    "            else:\n",
    "                return df[df[attr] == val]\n",
    "        else:\n",
    "            return super(ID3Continuous, self).eval_attr_condition(attr, df, val)\n",
    "    \n",
    "    def evaluate_test(self, row_value, condition, val):\n",
    "        if condition.strip().startswith(\"in\"):\n",
    "            val1, val2 = [float(i) for i in val.strip(\"[)\").split(\", \")]\n",
    "            return val1 <= row_value < val2\n",
    "        else:\n",
    "            return super(ID3Continuous, self).evaluate_test(row_value, condition, val)\n",
    "        \n",
    "    def get_test_condition(self, attr, value):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = value\n",
    "            return \" in \"\n",
    "        else:\n",
    "            return super(ID3Continuous, self).get_test_condition(attr, value)\n",
    "    \n",
    "    def get_test_value(self, attr, value):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = value\n",
    "            return \"[{}, {})\".format(str(value1), str(value2)) #[value1, value2]\n",
    "        else:\n",
    "            return super(ID3Continuous, self).get_test_value(attr, value)\n",
    "\n",
    "df_continuous = pd.DataFrame({\"Sky\":  [\"Blue\",\"Blue\",\"Dark\",\"Blue\",\"Gloomy\",\"Gloomy\", \"Dark\"],\n",
    "                              \"Temp\": [26, 24, 26, 24, 26, 24, 24]})\n",
    "labels =                              [\"Play\", \"Don't Play\", \"Play\", \"Don't Play\", \"Play\", \"Don't Play\", \"Don't Play\"]\n",
    "df_continuous_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                                   \"Temp\": [26, 7, 2]})\n",
    "id3_continuous = ID3Continuous(df_continuous, labels)\n",
    "id3_continuous.train()\n",
    "id3_continuous.test(df_continuous_test)\n",
    "id3_continuous._model.visualize()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "## 1.7 Decision Tree Regression\n",
    "\n",
    "We can extend the idea of ID3 from a discrete target function to a continuous target function (regression).\n",
    "\n",
    "***What should we use to make the current ID3 algorithm usable for continuous data ?*** (Click on **+** to see the answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "We need to change the Entropy which is meant for discrete values only. The Information Gain measure will essentially change for dealing with regression data. \n",
    "One possible way is to use standard deviation or variance to tell which attribute to split on. The one which maximizes the gain in weighted average of variance most is taken.\n",
    "At any given node $S$ we compute the variance as \n",
    "$$WVar(S, A) = \\sum_{v \\in A} (\\frac{|S_v|}{|S|}(\\sum_{<x_c, t_c> \\in S_v} (t_c - \\frac{\\sum_{<x_c, t_c> \\in S_v}x_c}{|S_v|})^2))$$\n",
    "If we write $Var(S_v) = \\frac{1}{|S_v|} (\\sum_{<x_c, t_c> \\in S_v} (t_c - \\frac{\\sum_{<x_c, t_c> \\in S_v}x_c}{|S_v|})^2)$\n",
    "So $WVar(S, A)$ becomes\n",
    "$$WVar(S, A) = \\sum_{v \\in A} \\frac{|S_v|^2}{|S|}Var(S_v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:07:02.569088Z",
     "start_time": "2020-01-10T02:07:02.342204Z"
    },
    "solution": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ TestData = {'Sky': 'Blue', 'Temp': 26} NodeLabel = 1.2 ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Gloomy', 'Temp': 7} NodeLabel = -1.23 ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Dark', 'Temp': 2} NodeLabel = -1.23 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"587pt\" height=\"131pt\"\r\n",
       " viewBox=\"0.00 0.00 587.00 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 583,-127 583,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"245\" cy=\"-105\" rx=\"189.267\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Temp&quot;, &quot;Gain&quot;:&quot;1.4605530612244897&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.2</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M114.253,-91.9824C82.8426,-86.7572 54.9121,-79.3706 43,-69 36.3536,-63.2137 32.4454,-54.6659 30.155,-46.2679\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"33.5447,-45.3761 28.0885,-36.2942 26.6903,-46.7964 33.5447,-45.3761\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"102.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[26.0, inf)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"169\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.2</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.56,-87.6946C182.439,-82.9361 175.096,-76.8273 170,-69 165.652,-62.3218 164.294,-54.0052 164.34,-46.0836\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.833,-46.2979 165.076,-36.0682 160.852,-45.7847 167.833,-46.2979\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[24.0, 25.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"321\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"321\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.23</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;4 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.699,-87.1414C285.388,-82.0746 293.063,-75.9765 299,-69 304.768,-62.2224 309.264,-53.6949 312.645,-45.6112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"315.971,-46.7102 316.226,-36.1184 309.421,-44.2391 315.971,-46.7102\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"370\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[&#45;inf, 24.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"468\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"468\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.23</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;5 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.824,-90.6459C392.348,-85.1983 422.566,-78.0211 436,-69 444.763,-63.1153 451.637,-53.9359 456.729,-45.0402\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"459.909,-46.5123 461.397,-36.0225 453.692,-43.2945 459.909,-46.5123\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"514.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[25.0, 26.0)&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0xc9fd1f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build on top of ID3Continuous\n",
    "import numpy\n",
    "class ID3Regression(ID3Continuous):\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[float]):\n",
    "        super(ID3Regression, self).__init__(train_data, labels)\n",
    "    \n",
    "    def get_distinct_labels(self, labels):\n",
    "        var = self.get_variance(labels)\n",
    "        if var > 10**-3:\n",
    "            return set(labels)\n",
    "        else:\n",
    "            return set([self.get_average(labels)])\n",
    "        \n",
    "    def get_variance(self, labels: typing.List[float]):\n",
    "        return numpy.var(labels, dtype='float64')\n",
    "    \n",
    "    def get_average(self, labels: typing.List[float]):\n",
    "        return numpy.average(labels)\n",
    "    \n",
    "    def get_best_attribute(self, df: pd.DataFrame, attributes: typing.List[str], labels: typing.List[float]):\n",
    "        max_variance_avg = -math.inf\n",
    "        split_attr = None\n",
    "        n = len(df)\n",
    "        total_variance = self.get_variance(labels)\n",
    "        for attr in attributes:\n",
    "            distinct_values = self.get_distinct_values(attr, df, labels)\n",
    "            curr_variance_avg = 0\n",
    "            for val in distinct_values:\n",
    "                new_df = self.eval_attr_condition(attr, df, val)\n",
    "                if len(new_df) == 0:\n",
    "                    continue\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_df[\"_index_\"]]\n",
    "                curr_variance_avg += (len(new_labels)**2 * self.get_variance(new_labels))/n\n",
    "            curr_variance_avg = total_variance - curr_variance_avg\n",
    "            if curr_variance_avg > max_variance_avg:\n",
    "                split_attr = attr\n",
    "                max_variance_avg = curr_variance_avg\n",
    "        return [split_attr, max_variance_avg]\n",
    "\n",
    "df_reg = pd.DataFrame({\"Sky\":  [\"Blue\",\"Blue\",\"Dark\",\"Blue\",\"Gloomy\",\"Gloomy\", \"Dark\"],\n",
    "                              \"Temp\": [26, 24, 26, 24, 26, 24, 24]})\n",
    "labels =                              [1.2, -1.2, 1.23, -1.23, 1.23, -1.23, -1.23]\n",
    "df_reg_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                                   \"Temp\": [26, 7, 2]})\n",
    "id3_reg = ID3Regression(df_reg, labels)\n",
    "id3_reg.train()\n",
    "id3_reg.test(df_continuous_test)\n",
    "id3_reg._model.visualize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
