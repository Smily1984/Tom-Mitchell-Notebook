{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Learning\n",
    "\n",
    "Decision tree learning is one of the most widely used and practical methods for inductive inference. It is a method for approximating discrete-valued functions that is robust to noisy data and capable of learning disjunctive expressions. This chapter describes a family of decision tree learning algorithms that includes widely used algorithms such as ID3, ASSISTANT, and C4.5. These decision tree learning methods search a completely expressive hypothesis space and thus avoid the difficulties of restricted hypothesis spaces. Their inductive bias is a preference for small trees over large trees.\n",
    "\n",
    "In general, decision trees represent a disjunction of conjunctions of constraints on the attribute values of instances. Each path from the tree root to a leaf corresponds to a conjunction of attribute tests, and the tree itself to a disjunction of these conjunctions. \n",
    "\n",
    "\n",
    "## 1.1 Appropriate problems for decision tree learning\n",
    "\n",
    "Decision tree is very helpful in scenarios where:\n",
    "- Where instances are represented as attribute value pairs. There are discrete values of attributes. For example, Temperature can be *Hot, Mild, Cold*\n",
    "- Target function has discrete output values. It can be binary (*yes* or *no*) or can have more than two classes.\n",
    "- Disjunctive descriptions may be required to express the hypothesis.\n",
    "- Training data may contain errors\n",
    "- Training data might have some missing attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "## 1.2 Basic Decision Tree Algorithm\n",
    "\n",
    "Most of the approaches are based on top-down greedy approaches of searching the right decision tree from the space of decision trees. It starts of by asking which attribute is statistically the best to split the data at root node.\n",
    "\n",
    "### 1.2.1 ID3 algorithm\n",
    "\n",
    "---\n",
    "***Alogirthm 1.2.1***:\n",
    "ID3(Examples, Target_attribute, Attributes):\n",
    "1. Create a root node.\n",
    "2. **If** all example in *Examples* are positive then ***return Root with label +***\n",
    "3. **If** all example in *Examples* are negative then ***return Root with label -***\n",
    "4. **If** *Attributes* is empty then ***return Root with label = most common Target_attribute in Examples***\n",
    "5. **Else**:\n",
    "   - $A \\leftarrow$ Best attribute from *Attributes* which best\\* classifies *Examples*\n",
    "   - Set $A$ as decision attribute for $Root$\n",
    "   - For each possible value $v_i$ of $A$:\n",
    "       - Add a new tree branch below *Root*, corresponding to the test $A = v_i$\n",
    "       - **Let** $Examples_{v_i}$ be the subset of *Examples* that have value $v_i$ for $A$\n",
    "       - **If** $Examples_{v_i}$ is empty:\n",
    "           - **Then** Below this new branch add a new leaf node with label = most common value of *Target_attribute in Examples*\n",
    "           - **Else** Below this new branch add a subtree ID3($Examples_{v_i}$, $Target\\_attribute$, $Attribute - \\{A\\}$)\n",
    "---\n",
    "**\\*Best**: Best attribute is the one with the highest information gain.\n",
    "\n",
    "### 1.2.2 How to decide the best attribute ?\n",
    "\n",
    "There are multiple way to decide the best attribute one of them is ***Information Gain***.\n",
    "\n",
    "### 1.2.3 Information Content\n",
    "\n",
    "This definition is taken from information theory. We define something called as *information content*. Given a random variable $X$ with a probability mass function $p_X(x)$, the self-information of measuring $X$ as outcome $x$ is defined as\n",
    " $$I_X(x) = - log_2(p_X(x))$$\n",
    "\n",
    " The unit of information is called *Shannon* (or simply bit).<br>\n",
    "**Below is the implementation of Information Content**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:12:43.298592Z",
     "start_time": "2020-02-25T19:12:43.037240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Ix(x)\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "def InformationContent(x):\n",
    "    assert 0 <= x <= 1\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return -math.log(x, 2)\n",
    "x = [i*0.001 for i in range(1, 1000)]\n",
    "y = [InformationContent(i) for i in x]\n",
    "plot.close()\n",
    "plot.title(\"Information Content\")\n",
    "plot.xlabel(r'$p_X(x)$')\n",
    "plot.ylabel(r'$I_X(x) = -log_2(p_X(x))$')\n",
    "plot.plot(x, y)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Information Gain\n",
    "Clearly *information content* is more in outcomes which are less frequent.\n",
    "Using this we define *entropy* as average $I_X(x)$ (information content) for a sample space $S$.\n",
    "$$Entropy(S) = -\\sum_{i \\in S} p_i log_2 p_i$$\n",
    "In other words, $Entropy(S) = E[I_x(x)]$ (expected or average information content)\n",
    "Entropy can be seen as the measure of average number of bits needed to communicate a message from space $S$. \n",
    "For more information on the rationale behind defining $Entropy$ like this read the following <a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)#Rationale\">Wiki Page</a>\n",
    "\n",
    "We define the Information Gain for a sample $S$ and attribute $A$ as:\n",
    "$$Gain(S, A) = Entropy(S) - \\sum_{v \\in A} \\frac{|S_v|}{|S|}Entropy(S_v)$$\n",
    "\n",
    "The *entropy* is minimum when each outcome is equally likely. (This can be seen in the entropy diagram)<br>\n",
    "**Below is the implementation of Information Gain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:12:39.556068Z",
     "start_time": "2020-02-25T19:12:39.508196Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InformationContent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a2d2b4aff517>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Entropy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-a2d2b4aff517>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Entropy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-a2d2b4aff517>\u001b[0m in \u001b[0;36mEntropy\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mEpsEquals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mInformationContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-a2d2b4aff517>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mEpsEquals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mInformationContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InformationContent' is not defined"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "def EpsEquals(f1:float, f2: float, eps: float=10**-6):\n",
    "    return abs(f1 - f2) <= eps\n",
    "\n",
    "def Entropy(p:typing.List[float]):\n",
    "    assert EpsEquals(sum(p), 1.0)\n",
    "    return sum([pi * InformationContent(pi) for pi in p])\n",
    "\n",
    "x = [[i * 0.001, 1 - i * 0.001] for i in range(1000)]\n",
    "y = [Entropy(xi) for xi in x]\n",
    "plot.close()\n",
    "plot.title(\"Entropy\")\n",
    "plot.xlabel(\"p\")\n",
    "plot.ylabel(r'$plog_2(p) +(1-p)log_2(1-p)$')\n",
    "plot.plot(x, y)\n",
    "plot.show()\n",
    "Entropy([1/2, 1/3, 1/18, 1 - 1/3 - 1/2 - 1/18 - 1/19 - 1/20, 1/19, 1/20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the implementation of ID3 decision tree algorithm**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:12:33.364857Z",
     "start_time": "2020-02-25T19:12:33.247587Z"
    },
    "code_folding": [
     74,
     197
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dd4cfcc8c187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    206\u001b[0m                         \"Grass\":[\"Yellow\", \"Yellow\", \"Yellow\"]})\n\u001b[0;32m    207\u001b[0m \u001b[0mid3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-dd4cfcc8c187>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-dd4cfcc8c187>\u001b[0m in \u001b[0;36mid3\u001b[1;34m(self, example, labels, attribute_set)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# We need to choose the best attribute and then recursively build the tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mbest_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattribute_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;31m# ID3._printExamples(\"Best attribute %s %s\" % (best_attr, entropy_value), example)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{{\\\"Attr\\\":\\\"{}\\\", \\\"Gain\\\":\\\"{}\\\"}}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-dd4cfcc8c187>\u001b[0m in \u001b[0;36mget_best_attribute\u001b[1;34m(self, df, attributes, labels)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcur_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcur_label_cnt_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcur_label_cnt_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mcur_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mcur_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mID3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mmax_gain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0msplit_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-dd4cfcc8c187>\u001b[0m in \u001b[0;36m_entropy\u001b[1;34m(freq)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mcum_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcum_sum\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Entropy' is not defined"
     ]
    }
   ],
   "source": [
    "#IMPORTANT NOTE\n",
    "#This piece of code is not intended for production scale and \n",
    "#should ideally be used for pedagogical purposes.\n",
    "#Use it at your own risk\n",
    "\n",
    "#ID3 implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "GRAPHVIZ_PATH = r'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + GRAPHVIZ_PATH\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_name:str=\"_null_\", label:str=\"_null_\", test:str=\"_null_\", is_leaf:bool=False):\n",
    "        self._children = []\n",
    "        self.name = node_name\n",
    "        self.label = label\n",
    "        self.test = test\n",
    "        self.leaf = is_leaf\n",
    "        pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    def add_child(self, node):\n",
    "        self._children.append(node)\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self._children\n",
    "    \n",
    "    def set_name(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "    def set_label(self, label: str):\n",
    "        self.label =str(label)\n",
    "        \n",
    "    def set_test(self, test: typing.List[str]):\n",
    "        self.test = test\n",
    "    \n",
    "    def set_leaf(self):\n",
    "        self.leaf = True\n",
    "    \n",
    "    def visualize(self):\n",
    "        digraph = Digraph(comment=\"Tree\")\n",
    "        Node._get_graph(self, digraph, [0])\n",
    "        return digraph\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_graph(node, digraph: Digraph, unique_suff:typing.List[int]):\n",
    "        unique_suff[0] += 1\n",
    "        curr_node_name = str(unique_suff[0])\n",
    "        digraph.node(curr_node_name, node.label)\n",
    "        if not node.leaf:\n",
    "            node._children.sort(key=lambda x: x.test[2])\n",
    "            for child in node._children:\n",
    "                child_name = str(unique_suff[0] + 1)\n",
    "                Node._get_graph(child, digraph, unique_suff)\n",
    "                digraph.edge(curr_node_name, child_name, label=\"%s %s '%s'\" % tuple(child.test))\n",
    "\n",
    "class ID3:\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[str], populate_inner_properties: bool=True):\n",
    "        self.attributes = list(train_data.columns)\n",
    "        self.distinct_labels = set(labels)\n",
    "        self.train_data: pd.DataFrame = train_data.copy(deep=True)\n",
    "        self.train_data[\"_index_\"] = range(0, len(train_data))\n",
    "        self.label_dictionary = {i:labels[i] for i in range(len(labels))}\n",
    "        self.labels = labels\n",
    "        self.attribute_values = None\n",
    "        self._model = None\n",
    "        if populate_inner_properties:\n",
    "            self.populate()\n",
    "    \n",
    "    def populate(self):\n",
    "        self.attribute_values = {attr: set(self.train_data[attr].unique()) for attr in self.attributes}\n",
    "    \n",
    "    @staticmethod\n",
    "    def _entropy(freq: typing.List[int]):\n",
    "        cum_sum = sum(freq)\n",
    "        p = [freq[i]/cum_sum for i in range(len(freq))]\n",
    "        entropy = Entropy(p)\n",
    "        return entropy\n",
    "    \n",
    "    def get_best_attribute(self, df: pd.DataFrame, attributes: typing.List[str], labels: typing.List[str]):\n",
    "        cur_label_cnt_dict = ID3._get_label_count_dict(labels)\n",
    "        cur_freq = [cur_label_cnt_dict[key] for key in cur_label_cnt_dict]\n",
    "        cur_total = sum(cur_freq)\n",
    "        cur_entropy = ID3._entropy(cur_freq)\n",
    "        max_gain = -math.inf\n",
    "        split_attr = None\n",
    "        for attr in attributes:\n",
    "            distinct_values = self.get_distinct_values(attr, df, labels)\n",
    "            partial = 0\n",
    "            gain = 0\n",
    "            for val in distinct_values:\n",
    "                new_df = self.eval_attr_condition(attr, df, val)\n",
    "                if len(new_df) == 0:\n",
    "                    continue\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_df[\"_index_\"]]\n",
    "                new_label_cnt_dict = ID3._get_label_count_dict(new_labels)\n",
    "                new_freq = [new_label_cnt_dict[key] for key in new_label_cnt_dict]\n",
    "                new_entropy = ID3._entropy(new_freq)\n",
    "                new_total = sum(new_freq)\n",
    "                new_partial = new_total / cur_total * new_entropy\n",
    "                partial += new_partial\n",
    "            gain = cur_entropy - partial\n",
    "            if gain > max_gain:\n",
    "                split_attr = attr\n",
    "                max_gain = gain\n",
    "        return [split_attr, max_gain]\n",
    "    \n",
    "    def get_distinct_values(self, attr: str, df: pd.DataFrame, labels: typing.List[str]):\n",
    "        return self.attribute_values[attr]\n",
    "    \n",
    "    def eval_attr_condition(self, attr, df, val):\n",
    "        return df[df[attr] == val]\n",
    "    \n",
    "    def get_test_condition(self, attr, value):\n",
    "        return \"==\"\n",
    "    \n",
    "    def get_test_value(self, attr, value):\n",
    "        return value\n",
    "    \n",
    "    def get_distinct_labels(self, labels):\n",
    "        return set(labels)        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_label_count_dict(labels: typing.List[str]):\n",
    "        distinct_labels = set(labels)\n",
    "        label_cnt_dict =  {l : labels.count(l) for l in distinct_labels}\n",
    "        return label_cnt_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_label_with_high_freq(labels: typing.List[str]):\n",
    "        label_cnt_dict = ID3._get_label_count_dict(labels)\n",
    "        maxi = -math.inf\n",
    "        max_label = labels[0]\n",
    "        for label in label_cnt_dict:\n",
    "            if label_cnt_dict[label] > maxi:\n",
    "                maxi = label_cnt_dict[label]\n",
    "                max_label = label\n",
    "        return max_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def _printExamples(name: str, df: pd.DataFrame):\n",
    "        print(\"------------------------\")\n",
    "        print(name)\n",
    "        print(df)\n",
    "        print(\"------------------------\")\n",
    "    \n",
    "    def id3(self, example: pd.DataFrame, labels: typing.List[str], attribute_set: set):\n",
    "        example[\"_labels_\"] = labels\n",
    "        root_node = Node()\n",
    "        distinct_labels = self.get_distinct_labels(labels)\n",
    "        if len(distinct_labels) == 1: # If all labels are of same type\n",
    "            root_node.set_label(labels[0])\n",
    "            root_node.set_name(\"LeafNode\")\n",
    "            root_node.set_leaf()\n",
    "        elif len(attribute_set) == 0: # If there are no attributes left\n",
    "            root_node.set_label(ID3._get_label_with_high_freq(labels))\n",
    "            root_node.set_name(\"LeafNode\")\n",
    "            root_node.set_leaf()\n",
    "        else: # We need to choose the best attribute and then recursively build the tree\n",
    "            best_attr, entropy_value = self.get_best_attribute(example, list(attribute_set), labels)\n",
    "            # ID3._printExamples(\"Best attribute %s %s\" % (best_attr, entropy_value), example)\n",
    "            root_node.set_label(\"{{\\\"Attr\\\":\\\"{}\\\", \\\"Gain\\\":\\\"{}\\\"}}\".format(best_attr, entropy_value))\n",
    "            for value in self.get_distinct_values(best_attr, example, labels):\n",
    "                new_examples = self.eval_attr_condition(best_attr, example, value)\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_examples[\"_index_\"]]\n",
    "                new_examples[\"_index_\"] = range(0, len(new_examples))\n",
    "                new_child_node:Node = None\n",
    "                new_attribute_set = set(attribute_set)\n",
    "                new_attribute_set.remove(best_attr)\n",
    "                if len(new_examples) == 0:\n",
    "                    new_child_node = Node()\n",
    "                    new_child_node.set_label(ID3._get_label_with_high_freq(labels))\n",
    "                    new_child_node.set_leaf()\n",
    "                else:\n",
    "                    new_child_node = self.id3(new_examples, new_labels, new_attribute_set)\n",
    "                new_child_node.test = [best_attr, self.get_test_condition(best_attr, value), self.get_test_value(best_attr, value)]\n",
    "                root_node.add_child(new_child_node)\n",
    "        return root_node\n",
    "    \n",
    "    def train(self):\n",
    "        self._model = self.id3(self.train_data, self.labels, set(self.attributes))\n",
    "    \n",
    "    def evaluate_test(self, row_value, condition, val):\n",
    "        return row_value == val\n",
    "    \n",
    "    def test_row(self, cur_node, df_row):\n",
    "        if cur_node.leaf:\n",
    "            print(\"Output: [\", \"TestData =\",df_row.to_dict(), \"NodeLabel =\", cur_node.label, \"]\")\n",
    "            print()\n",
    "            return cur_node.label\n",
    "        else:\n",
    "            for child in cur_node._children:\n",
    "                attr, condition, value = child.test\n",
    "                if self.evaluate_test(df_row[attr], condition, value):\n",
    "                    # print(\"Checking Node:[\", attr, condition, value, \"TestData =\", df_row.to_dict(), \"NodeLabel =\", child.label, \"]\")\n",
    "                    return self.test_row(child, df_row)\n",
    "    \n",
    "    def test(self, df: pd.DataFrame):\n",
    "        return [self.test_row(self._model, row) for index, row in df.iterrows()]\n",
    "df = pd.DataFrame({\"Sky\":[\"Blue\", \"Blue\", \"Dark\", \"Dark\", \"Gloomy\"],\n",
    "                   \"Grass\":[\"Green\", \"Yellow\", \"Green\", \"Yellow\", \"Green\"]})\n",
    "labels =               [\"Play\", \"Don't Play\", \"Don't Play\", \"Don't Play\", \"Don't Play\"]\n",
    "df_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                        \"Grass\":[\"Yellow\", \"Yellow\", \"Yellow\"]})\n",
    "id3 = ID3(df, labels)\n",
    "id3.train()\n",
    "id3.test(df_test)\n",
    "id3._model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Hypothesis Space For Decision Tree\n",
    "\n",
    "The set of all possible decision trees is the hypothesis space for Decision Tree. It is hypothesis space of decision tree is *complete space* of finite discrete valued functions, relative to the attributes.\n",
    "Some important features about ID3 algorithm:\n",
    "- ID3 maintains only a single current hypothesis as it searches through the space of decision trees. \n",
    "- This contrasts, for example, with the version space *Candidate-Elimination* method, which maintains the set of all hypotheses consistent with the available training examples. \n",
    "- ID3 doesn't have the capability to determine how many alternative decision tree are consistent with the training data.\n",
    "- ID3 doesn't perform any backtracking. It uses kind of greedy hill climbing approach. (This gap can be filled by using post-pruning)\n",
    "- ID3 can be modified to handle noisy data. ID3 uses all training examples at each step in the search to make statistically based decisions regarding how to refine its current hypothesis. This contrasts with methods that make decisions incrementally, based on individual training examples (e.g., Find-S or Candidate-Elimination). One advantage of using statistical properties of all the examples (e.g., information gain) is that the resulting search is much less sensitive to errors in individual training examples. ID3 can be easily extended to handle noisy training data by modifying its termination criterion to accept hypotheses that imperfectly fit the training data\n",
    "\n",
    "# 1.4 Inductive Bias For Decision Tree\n",
    "\n",
    "Since ID3 follows heuristics to get to the first tree in a simple to complex tree search (like hill climbing). Therefore decision tree prefers shorter trees over larger ones. But this is not very evident because of the heuristics.\n",
    "\n",
    "**Approximate Inductive Bias** : Shorter trees are preferred.\n",
    "A better bias will be to include the heuristic in the bias.\n",
    "\n",
    "**A more closer Inductive Bias**: Shorter trees are preferred over longer trees. Trees that place high information gain attributes close to the root are preferred over those that do not.\n",
    "\n",
    "Decision tree has a *restriction bias* whereas candidate elimination has *preference bias*. *Restriction bias* is when the hypothesis space is searched incompletely and not all consistent hypothesis are considered, the algorithm stops at the first consistent hypothesis. Whereas in *preference bias* the search space itself is restricted.\n",
    "\n",
    "Decision tree prefers a shorter hypothesis based on ***Ocam Razor's Principle***, prefer the simplest hypothesis which fits the data. The Ocam Razor too has problems. The difficulty here is that there are very many small sets of hypotheses that one can define and most of them rather arcane.\n",
    "\n",
    "Why should we believe that the small set of hypotheses consisting of decision trees with short descriptions should be any more relevant than the multitude of other small sets of hypotheses that we might define? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Issues With Decision Trees\n",
    "- **Overfitting The Training Data** : This is quite possible because decision tree can grow till is able to classify the training example and stop growing after that. This can happen when the sample is size is small or there is noise in data.\n",
    "    - **Overfit definition**: Given a hypothesis space $H$, a hypothesis $h \\in H$ is said to overfit the training data if there exists some alternative hypothesis $h' \\in H$, such that h has smaller error than $h'$ over the training examples, but $h'$ has a smaller error than $h$ over the entire distribution of instances.\n",
    "    - **Avoiding overfitting**:\n",
    "        - Stop the tree growth before it perfectly fits the training data.\n",
    "        - Prune the tree after it has been trained.\n",
    "    - Criteria getting used for determining the final size of the tree:\n",
    "        - Use different set of examples other than the training one to evaluate the utility of post-puring of nodes from tree.\n",
    "        - Use all available data for training but use a statistical test like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "## 1.6 Dealing with continuous data for attributes\n",
    "\n",
    "One way to deal with continuous data is partition it into discrete values in a discreet way such that it ends up maximizing the overall information gain.\n",
    "\n",
    "One way to do this by sorting the continuous values and then checking where the values of the target function are changing.\n",
    "This approach is prescribed in [Fayyad's (1992) paper](http://web.cs.iastate.edu/~honavar/fayyad.pdf) .<br>\n",
    "\n",
    "For example consider the following table:<br>\n",
    "\n",
    "|.|.|.|.|.|.|.|\n",
    "|-|-----|----|------|------|----|----|\n",
    "|Temperature|40|48|60|72|80|90|\n",
    "|PlayTennis|No|No|Yes|Yes|Yes|No|\n",
    "\n",
    "In the above table the change happens at Temperature 48 and 60 and 80 and 90, so we introduce two discrete candidate attributes $Temperature_{>\\frac{(48 + 60)}{2}} = Temperature_{>54}$ and $Temperature_{>\\frac{(80 + 90)}{2}} = Temperature_{>85}$\n",
    "\n",
    "**Below is the implementation of ID3 with continuous attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:15:33.308383Z",
     "start_time": "2020-01-10T02:15:32.944591Z"
    },
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ TestData = {'Sky': 'Blue', 'Temp': 26} NodeLabel = Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Gloomy', 'Temp': 7} NodeLabel = Don't Play ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Dark', 'Temp': 2} NodeLabel = Don't Play ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"386pt\" height=\"131pt\"\r\n",
       " viewBox=\"0.00 0.00 386.27 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 382.266,-127 382.266,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"189.133\" cy=\"-105\" rx=\"189.267\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"189.133\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Temp&quot;, &quot;Gain&quot;:&quot;0.9852281360342516&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"116.133\" cy=\"-18\" rx=\"48.9926\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"116.133\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Don&#39;t Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.192,-87.5486C129.257,-82.7961 122.077,-76.727 117.133,-69 112.839,-62.2875 111.495,-53.9613 111.538,-46.0413\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.031,-46.2601 112.262,-36.0335 108.05,-45.7548 115.031,-46.2601\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"179.133\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[&#45;inf, 25.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"263.133\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"263.133\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Play</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.341,-87.1446C227.836,-82.044 235.339,-75.9289 241.133,-69 246.842,-62.1726 251.322,-53.6319 254.707,-45.5513\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.029,-46.6605 258.301,-36.0691 251.484,-44.1793 258.029,-46.6605\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"309.633\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[25.0, inf)&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0xb07a730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build on top of alread existing ID3 algorithm, inheriting from ID3 class\n",
    "\n",
    "class ID3Continuous(ID3):\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[str]):\n",
    "        super(ID3Continuous, self).__init__(train_data, labels, populate_inner_properties=False)\n",
    "        # Call attributes according the overriden values\n",
    "        data_types_dict = dict(train_data.dtypes)\n",
    "        self.data_types_dict = {attr: str(data_types_dict[attr]) for attr in data_types_dict}\n",
    "        self.continuous_attr = None\n",
    "        self.populate()\n",
    "    \n",
    "    def populate(self):\n",
    "        self.continuous_attr = set([attr for attr in self.data_types_dict if self.data_types_dict[attr] in ['float64', 'int64']])\n",
    "        self.attribute_values = {attr: set(self.train_data[attr].unique()) for attr in self.attributes if not attr in self.continuous_attr}\n",
    "    \n",
    "    def get_distinct_values(self, attr: str, df: pd.DataFrame, labels: typing.List[str]):\n",
    "        # If it is not continuous attr simply return go to base class implementation\n",
    "        if not attr in self.continuous_attr:\n",
    "            return super(ID3Continuous, self).get_distinct_values(attr, df, labels)\n",
    "        else:\n",
    "            sorted_df = df.sort_values(attr)\n",
    "            sorted_labels = [labels[idx] for idx in sorted_df[\"_index_\"]]\n",
    "            idx = 1\n",
    "            changed_values = [-math.inf]\n",
    "            #ID3._printExamples(\"Before computing change\", sorted_df)\n",
    "            while idx < len(sorted_labels):\n",
    "                if sorted_labels[idx] != sorted_labels[idx - 1]:\n",
    "                    v1 = sorted_df.iloc[idx][attr]\n",
    "                    v2 = sorted_df.iloc[idx - 1][attr]\n",
    "                    changed_values.append((v1 + v2)/2)\n",
    "                idx += 1\n",
    "            if len(changed_values) == 0 and len(sorted_df) == 1:\n",
    "                changed_values.append(sorted_df.iloc[0][attr])\n",
    "            changed_values = list(set(changed_values))\n",
    "            changed_values.sort()\n",
    "            vals = set()\n",
    "            idxValues = 1\n",
    "            vals.add((-math.inf, \"=<\", \"<\", changed_values[idxValues]))\n",
    "            while idxValues < len(changed_values):\n",
    "                vals.add((changed_values[idxValues - 1], \"=<\", \"<\", changed_values[idxValues]))\n",
    "                idxValues += 1\n",
    "            changed_values.append(math.inf)\n",
    "            vals.add((changed_values[idxValues - 1], \"=<\", \"<\", changed_values[idxValues]))\n",
    "            #print(\"changed vals\", vals)\n",
    "            return vals\n",
    "    \n",
    "    def eval_attr_condition(self, attr, df, val):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = val\n",
    "            if condition1 == \"=<\" and condition2 == \"<\":\n",
    "                return df[(value1 <= df[attr]) & (df[attr] < value2)]\n",
    "            else:\n",
    "                return df[df[attr] == val]\n",
    "        else:\n",
    "            return super(ID3Continuous, self).eval_attr_condition(attr, df, val)\n",
    "    \n",
    "    def evaluate_test(self, row_value, condition, val):\n",
    "        if condition.strip().startswith(\"in\"):\n",
    "            val1, val2 = [float(i) for i in val.strip(\"[)\").split(\", \")]\n",
    "            return val1 <= row_value < val2\n",
    "        else:\n",
    "            return super(ID3Continuous, self).evaluate_test(row_value, condition, val)\n",
    "        \n",
    "    def get_test_condition(self, attr, value):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = value\n",
    "            return \" in \"\n",
    "        else:\n",
    "            return super(ID3Continuous, self).get_test_condition(attr, value)\n",
    "    \n",
    "    def get_test_value(self, attr, value):\n",
    "        if attr in self.continuous_attr:\n",
    "            value1, condition1, condition2, value2 = value\n",
    "            return \"[{}, {})\".format(str(value1), str(value2)) #[value1, value2]\n",
    "        else:\n",
    "            return super(ID3Continuous, self).get_test_value(attr, value)\n",
    "\n",
    "df_continuous = pd.DataFrame({\"Sky\":  [\"Blue\",\"Blue\",\"Dark\",\"Blue\",\"Gloomy\",\"Gloomy\", \"Dark\"],\n",
    "                              \"Temp\": [26, 24, 26, 24, 26, 24, 24]})\n",
    "labels =                              [\"Play\", \"Don't Play\", \"Play\", \"Don't Play\", \"Play\", \"Don't Play\", \"Don't Play\"]\n",
    "df_continuous_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                                   \"Temp\": [26, 7, 2]})\n",
    "id3_continuous = ID3Continuous(df_continuous, labels)\n",
    "id3_continuous.train()\n",
    "id3_continuous.test(df_continuous_test)\n",
    "id3_continuous._model.visualize()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "## 1.7 Decision Tree Regression\n",
    "\n",
    "We can extend the idea of ID3 from a discrete target function to a continuous target function (regression).\n",
    "\n",
    "***What should we use to make the current ID3 algorithm usable for continuous data ?*** (Click on **+** to see the answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "We need to change the Entropy which is meant for discrete values only. The Information Gain measure will essentially change for dealing with regression data. \n",
    "One possible way is to use standard deviation or variance to tell which attribute to split on. The one which maximizes the gain in weighted average of variance most is taken.\n",
    "At any given node $S$ we compute the variance as \n",
    "$$WVar(S, A) = \\sum_{v \\in A} (\\frac{|S_v|}{|S|}(\\sum_{<x_c, t_c> \\in S_v} (t_c - \\frac{\\sum_{<x_c, t_c> \\in S_v}x_c}{|S_v|})^2))$$\n",
    "If we write $Var(S_v) = \\frac{1}{|S_v|} (\\sum_{<x_c, t_c> \\in S_v} (t_c - \\frac{\\sum_{<x_c, t_c> \\in S_v}x_c}{|S_v|})^2)$\n",
    "So $WVar(S, A)$ becomes\n",
    "$$WVar(S, A) = \\sum_{v \\in A} \\frac{|S_v|^2}{|S|}Var(S_v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T02:15:33.549199Z",
     "start_time": "2020-01-10T02:15:33.312642Z"
    },
    "solution": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ TestData = {'Sky': 'Blue', 'Temp': 26} NodeLabel = 1.2 ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Gloomy', 'Temp': 7} NodeLabel = -1.23 ]\n",
      "\n",
      "Output: [ TestData = {'Sky': 'Dark', 'Temp': 2} NodeLabel = -1.23 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"589pt\" height=\"131pt\"\r\n",
       " viewBox=\"0.00 0.00 589.25 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 585.247,-127 585.247,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"252.247\" cy=\"-105\" rx=\"189.267\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"252.247\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Temp&quot;, &quot;Gain&quot;:&quot;1.4605530612244897&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"29.2474\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"29.2474\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.23</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.281,-92.2698C86.0933,-87.0505 57.4675,-79.5951 45.2474,-69 38.5893,-63.2272 34.6781,-54.6827 32.3888,-46.2836\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"35.7782,-45.3904 30.325,-36.3068 28.9233,-46.8085 35.7782,-45.3904\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"107.247\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[&#45;inf, 24.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"176.247\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"176.247\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.2</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.807,-87.6946C189.686,-82.9361 182.343,-76.8273 177.247,-69 172.9,-62.3218 171.541,-54.0052 171.587,-46.0836\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.081,-46.2979 172.323,-36.0682 168.099,-45.7847 175.081,-46.2979\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"241.747\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[24.0, 25.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"328.247\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.247\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.23</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;4 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.947,-87.1414C292.636,-82.0746 300.31,-75.9765 306.247,-69 312.016,-62.2224 316.511,-53.6949 319.892,-45.6112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.218,-46.7102 323.474,-36.1184 316.669,-44.2391 323.218,-46.7102\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"379.747\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[25.0, 26.0)&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"480.247\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"480.247\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.2</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;5 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M370.066,-90.8772C403.441,-85.445 434.452,-78.2185 448.247,-69 457.151,-63.0501 464.099,-53.6931 469.211,-44.6749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"472.438,-46.0529 473.88,-35.5567 466.207,-42.8626 472.438,-46.0529\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"521.747\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temp &#160;in &#160;&#39;[26.0, inf)&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0xc79fa50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build on top of ID3Continuous\n",
    "import numpy\n",
    "class ID3Regression(ID3Continuous):\n",
    "    def __init__(self, train_data: pd.DataFrame, labels: typing.List[float]):\n",
    "        super(ID3Regression, self).__init__(train_data, labels)\n",
    "    \n",
    "    def get_distinct_labels(self, labels):\n",
    "        var = self.get_variance(labels)\n",
    "        if var > 10**-3:\n",
    "            return set(labels)\n",
    "        else:\n",
    "            return set([self.get_average(labels)])\n",
    "        \n",
    "    def get_variance(self, labels: typing.List[float]):\n",
    "        return numpy.var(labels, dtype='float64')\n",
    "    \n",
    "    def get_average(self, labels: typing.List[float]):\n",
    "        return numpy.average(labels)\n",
    "    \n",
    "    def get_best_attribute(self, df: pd.DataFrame, attributes: typing.List[str], labels: typing.List[float]):\n",
    "        max_variance_avg = -math.inf\n",
    "        split_attr = None\n",
    "        n = len(df)\n",
    "        total_variance = self.get_variance(labels)\n",
    "        for attr in attributes:\n",
    "            distinct_values = self.get_distinct_values(attr, df, labels)\n",
    "            curr_variance_avg = 0\n",
    "            for val in distinct_values:\n",
    "                new_df = self.eval_attr_condition(attr, df, val)\n",
    "                if len(new_df) == 0:\n",
    "                    continue\n",
    "                new_labels = [labels[int(str(idx))] for idx in new_df[\"_index_\"]]\n",
    "                curr_variance_avg += (len(new_labels)**2 * self.get_variance(new_labels))/n\n",
    "            curr_variance_avg = total_variance - curr_variance_avg\n",
    "            if curr_variance_avg > max_variance_avg:\n",
    "                split_attr = attr\n",
    "                max_variance_avg = curr_variance_avg\n",
    "        return [split_attr, max_variance_avg]\n",
    "\n",
    "df_reg = pd.DataFrame({\"Sky\":  [\"Blue\",\"Blue\",\"Dark\",\"Blue\",\"Gloomy\",\"Gloomy\", \"Dark\"],\n",
    "                              \"Temp\": [26, 24, 26, 24, 26, 24, 24]})\n",
    "labels =                              [1.2, -1.2, 1.23, -1.23, 1.23, -1.23, -1.23]\n",
    "df_reg_test = pd.DataFrame({\"Sky\":[\"Blue\", \"Gloomy\", \"Dark\"],\n",
    "                                   \"Temp\": [26, 7, 2]})\n",
    "id3_reg = ID3Regression(df_reg, labels)\n",
    "id3_reg.train()\n",
    "id3_reg.test(df_continuous_test)\n",
    "id3_reg._model.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:14:01.030624Z",
     "start_time": "2020-02-25T19:13:59.312992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file InputOutputExamples\\InputOutputExamples\\TestCase1\\TrainingExamples1.csv\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"801pt\" height=\"218pt\"\r\n",
       " viewBox=\"0.00 0.00 801.00 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-214 797,-214 797,4 -4,4\"/>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"220\" cy=\"-192\" rx=\"202.264\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Outlook&quot;, &quot;Gain&quot;:&quot;0.24053300404228128&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.441,-175.437C122.978,-170.476 104.952,-164.101 89,-156 74.5149,-148.644 60.267,-137.51 49.0894,-127.613\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.2734,-124.868 41.5334,-120.698 46.5474,-130.032 51.2734,-124.868\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"152.5\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outlook == &#39;Overcast&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"220\" cy=\"-105\" rx=\"147.574\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Temperature&quot;, &quot;Gain&quot;:&quot;1.0&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220,-173.799C220,-162.163 220,-146.548 220,-133.237\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.5,-133.175 220,-123.175 216.5,-133.175 223.5,-133.175\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outlook == &#39;Rain&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>7</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"586\" cy=\"-105\" rx=\"200.665\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"586\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">{&quot;Attr&quot;:&quot;Humidity&quot;, &quot;Gain&quot;:&quot;0.9182958340544896&quot;}</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;7 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>1&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.842,-175.012C350.983,-160.58 442.365,-139.358 507.363,-124.263\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"508.208,-127.66 517.157,-121.988 506.624,-120.841 508.208,-127.66\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"481\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outlook == &#39;Sunny&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"68\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.246,-91.094C111.266,-85.941 97.9178,-78.8195 87,-69 80.251,-62.9299 75.8858,-54.2054 73.068,-45.7386\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"76.4425,-44.8095 70.4209,-36.0923 69.6921,-46.662 76.4425,-44.8095\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"151.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temperature == &#39;Cool&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"220\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220,-86.799C220,-75.1626 220,-59.5479 220,-46.2368\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.5,-46.1754 220,-36.1754 216.5,-46.1755 223.5,-46.1754\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temperature == &#39;Hot&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>6</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"365\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"365\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;6 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.703,-90.221C319.243,-85.1895 332.287,-78.3346 343,-69 349.989,-62.9099 354.849,-54.1808 358.186,-45.7158\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.558,-46.6682 361.44,-36.074 354.926,-44.4295 361.558,-46.6682\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Temperature == &#39;Mild&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>8</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"550\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"550\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M563.663,-86.8255C558.57,-81.6921 553.829,-75.641 551,-69 548.04,-62.0506 546.976,-54.05 546.862,-46.5152\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"550.366,-46.4528 547.233,-36.3317 543.371,-46.1974 550.366,-46.4528\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"605\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Humidity == &#39;High&#39;</text>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>9</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"681\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.259,-87.4143C642.615,-82.5504 651.766,-76.4732 659,-69 665.284,-62.5083 669.937,-53.9241 673.304,-45.7037\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"676.695,-46.6165 676.795,-36.0221 670.11,-44.2419 676.695,-46.6165\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"731.5\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Humidity == &#39;Normal&#39;</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x169b1e30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f_name = 'InputOutputExamples\\\\InputOutputExamples\\\\TestCase{0}\\\\TrainingExamples1.csv'.format(\"1\")\n",
    "print(\"Reading file {}\".format(f_name))\n",
    "df = pd.read_csv(f_name, delim_whitespace=True)\n",
    "labels = df['PlayTennis'].tolist()\n",
    "df.drop('PlayTennis', axis=1, inplace=True)\n",
    "id3 = ID3(df, labels)\n",
    "id3.train()\n",
    "tree = id3._model.visualize()\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
